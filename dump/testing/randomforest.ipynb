{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "171266a7",
   "metadata": {},
   "source": [
    "# Random Forest Classification of X-ray Images\n",
    "\n",
    "This notebook uses scikit-learn random forest to classify X-ray images into good coverage and poor coverage. \n",
    "\n",
    "## Import packages, define metrics, prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e27bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0167c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countZeroPixels(image):\n",
    "    \"\"\"Return the number of value-zero pixels in the image.\"\"\"\n",
    "    image=image.flatten()\n",
    "    return len(image)-np.count_nonzero(image)\n",
    "\n",
    "def getImageContrast(image):\n",
    "    \"\"\"Calculate a simple measure of the image contrast.\"\"\"\n",
    "    image=image.flatten()\n",
    "    image = image[image>0]\n",
    "    maxp = np.max(image)\n",
    "    minp = np.min(image)\n",
    "    return (maxp-minp)/(maxp+minp)\n",
    "\n",
    "def npixelsAboveNoise(image,threshold=5):\n",
    "    \"\"\"Calculate the number pixels above X*sigma of the noise.\"\"\"\n",
    "    image=image.flatten()\n",
    "    image=image[image>0]\n",
    "    rmsnoise = np.sqrt(np.mean(image**2.))\n",
    "    return len(image[np.where(image>threshold*rmsnoise)])\n",
    "\n",
    "def meanSepBrightPixels(image,threshold=5):\n",
    "    \"\"\"Return the mean separation (in px) between bright pixels.\"\"\"\n",
    "    image=image.flatten()\n",
    "    image=image[image>0]\n",
    "    rmsnoise = np.sqrt(np.mean(image**2.))\n",
    "    sel = np.where(image>threshold*rmsnoise)\n",
    "    if len(sel[0])==0:\n",
    "        return 300\n",
    "    else:\n",
    "        return (90000/len(image[sel]))**0.5\n",
    "\n",
    "def medianBrightYPosition(image,threshold=10):\n",
    "    \"\"\"Compute the median y-value among bright pixels.\"\"\"\n",
    "    rmsnoise = np.sqrt(np.mean(image**2.))\n",
    "    positions = np.where(image>threshold*rmsnoise)\n",
    "    return np.median(positions[0])\n",
    "\n",
    "def medianBrightXPosition(image, threshold=10):\n",
    "    \"\"\"Compute the median x-value among bright pixels.\"\"\"\n",
    "    rmsnoise = np.sqrt(np.mean(image**2.))\n",
    "    positions = np.where(image>threshold*rmsnoise)\n",
    "    return np.median(positions[1])\n",
    "\n",
    "def lr_contrast(image):\n",
    "    # left and right sections of image\n",
    "    left = image[:, :150]\n",
    "    right = image[:, 150:]\n",
    "    return np.abs(getImageContrast(left)-getImageContrast(right))\n",
    "\n",
    "def ud_contrast(image):\n",
    "    # left and right sections of image\n",
    "    up = image[150:, :]\n",
    "    down = image[:150, :]\n",
    "    return np.abs(getImageContrast(up)-getImageContrast(down))\n",
    "\n",
    "def triangular_contrast1(image):\n",
    "    # get upper, lower triangle\n",
    "    upper = np.triu(image)\n",
    "    lower = np.tril(image)\n",
    "    return np.abs(getImageContrast(upper)-getImageContrast(lower))\n",
    "\n",
    "def triangular_contrast2(image):\n",
    "    # get upper, lower triangle\n",
    "    upper = np.triu(np.fliplr(image))\n",
    "    lower = np.tril(np.fliplr(image))\n",
    "    return np.abs(getImageContrast(upper)-getImageContrast(lower))\n",
    "\n",
    "def ud_difference(image, threshold=10):\n",
    "    # left and right sections of image\n",
    "    rmsnoise = np.sqrt(np.mean(image**2.))\n",
    "    up = image[150:, :]\n",
    "    down = image[:150, :]\n",
    "    n_bright_up = len(up[up>threshold*rmsnoise])\n",
    "    n_bright_down = len(down[down>threshold*rmsnoise])\n",
    "    return np.abs(n_bright_up-n_bright_down)\n",
    "\n",
    "def lr_difference(image, threshold=10):\n",
    "    # left and right sections of image\n",
    "    rmsnoise = np.sqrt(np.mean(image**2.))\n",
    "    left = image[:, :150]\n",
    "    right = image[:, 150:]\n",
    "    n_bright_l = len(left[left>threshold*rmsnoise])\n",
    "    n_bright_r = len(right[right>threshold*rmsnoise])\n",
    "    return np.abs(n_bright_l-n_bright_r)\n",
    "\n",
    "def tri_difference1(image,threshold=10):\n",
    "    # get upper, lower triangle\n",
    "    rmsnoise = np.sqrt(np.mean(image**2.))\n",
    "    upper = np.triu(image)\n",
    "    lower = np.tril(image)\n",
    "    n_upper = len(upper[upper>threshold*rmsnoise])\n",
    "    n_lower = len(lower[lower>threshold*rmsnoise])\n",
    "    return np.abs(n_upper-n_lower)\n",
    "\n",
    "def tri_difference2(image,threshold=10):\n",
    "    # get upper, lower triangle\n",
    "    rmsnoise = np.sqrt(np.mean(image**2.))\n",
    "    upper = np.triu(np.fliplr(image))\n",
    "    lower = np.tril(np.fliplr(image))\n",
    "    n_upper = len(upper[upper>threshold*rmsnoise])\n",
    "    n_lower = len(lower[lower>threshold*rmsnoise])\n",
    "    return np.abs(n_upper-n_lower)\n",
    "\n",
    "def lr_zero(image, threshold=10):\n",
    "    # left and right sections of image\n",
    "    left = image[:, :150]\n",
    "    right = image[:, 150:]\n",
    "    n_bright_l = len(left[left==0])\n",
    "    n_bright_r = len(right[right==0])\n",
    "    return np.abs(n_bright_l-n_bright_r)\n",
    "\n",
    "def ud_zero(image, threshold=10):\n",
    "    # left and right sections of image\n",
    "    up = image[150:, :]\n",
    "    down = image[:150, :]\n",
    "    n_bright_up = len(up[up==0])\n",
    "    n_bright_down = len(down[down==0])\n",
    "    return np.abs(n_bright_up-n_bright_down)\n",
    "\n",
    "def symmetry_lr(image, clipsigma=10):\n",
    "    orig = np.copy(image)\n",
    "    clippedmean, jk, jk = sigma_clipped_stats(image[image!=0], sigma=10, maxiters=2, cenfunc=np.mean)\n",
    "    image[image>clipsigma*clippedmean] = clippedmean\n",
    "    flipped = np.fliplr(image)\n",
    "    diff = np.sum([image, -1*flipped], axis=0)\n",
    "    return np.sqrt(np.mean(diff**2.))\n",
    "\n",
    "def symmetry_ud(image, clipsigma=10):\n",
    "    orig = np.copy(image)\n",
    "    clippedmean, jk, jk = sigma_clipped_stats(image[image!=0], sigma=10, maxiters=2, cenfunc=np.mean)\n",
    "    image[image>clipsigma*clippedmean] = clippedmean\n",
    "    flipped = np.flipud(image)\n",
    "    diff = np.sum([image, -1*flipped], axis=0)\n",
    "    return np.sqrt(np.mean(diff**2.))\n",
    "\n",
    "\n",
    "metadata_funcs = [countZeroPixels, symmetry_lr, symmetry_ud]#, ud_difference, lr_difference, lr_zero, ud_zero]\n",
    "#metadata_funcs = [ud_difference, lr_difference, lr_zero, ud_zero, meanSepBrightPixels,\\\n",
    "#                  npixelsAboveNoise, getImageContrast, countZeroPixels, tri_difference1, tri_difference2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a2bde",
   "metadata": {},
   "source": [
    "## Metadata proof of concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41775da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "testimage = fits.open('/srv/scratch/zhutchen/khess_images/poor_coverage/RASS-Int_Hard_grp9530.0_.fits')[0].data\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(testimage)\n",
    "plt.show()\n",
    "\n",
    "[fx(testimage) for fx in metadata_funcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testimage = fits.open('/srv/scratch/zhutchen/khess_images/poor_coverage/RASS-Int_Hard_grp3562.0_.fits')[0].data\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(testimage)\n",
    "plt.show()\n",
    "\n",
    "[fx(testimage) for fx in metadata_funcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5d7c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "testimage = fits.open('/srv/scratch/zhutchen/khess_images/nondetections/RASS-Int_Hard_grp10007.0_.fits')[0].data\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(testimage)\n",
    "plt.show()\n",
    "\n",
    "[fx(testimage) for fx in metadata_funcs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467377c1",
   "metadata": {},
   "source": [
    "# Create training/validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5556ba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesXgood = []\n",
    "labelsygood = []\n",
    "imagesXpoor = []\n",
    "labelsypoor = []\n",
    "\n",
    "dpath = \"/srv/scratch/zhutchen/khess_images/detections/\"\n",
    "for f in os.listdir(dpath):\n",
    "    if f.endswith('.fits'):\n",
    "        #imagesX.append(np.array(fits.open(dpath+f)[0].data).flatten())\n",
    "        image = fits.open(dpath+f)[0].data\n",
    "        imagesXgood.append(np.array([fx(image) for fx in metadata_funcs]))\n",
    "        labelsygood.append('good_coverage')\n",
    "\n",
    "ndpath = \"/srv/scratch/zhutchen/khess_images/nondetections/\"\n",
    "for f in os.listdir(ndpath):\n",
    "    if f.endswith('.fits'):\n",
    "        #imagesX.append(np.array(fits.open(ndpath+f)[0].data).flatten())\n",
    "        image = fits.open(ndpath+f)[0].data\n",
    "        imagesXgood.append(np.array([fx(image) for fx in metadata_funcs]))\n",
    "        labelsygood.append('good_coverage')\n",
    "\n",
    "i=0\n",
    "pcpath = \"/srv/scratch/zhutchen/khess_images/poor_coverage_augmented/\"\n",
    "for f in os.listdir(pcpath):\n",
    "    if f.endswith('.fits') and i>-1:\n",
    "        #imagesX.append(np.array(fits.open(pcpath+f)[0].data).flatten()) #flatten each 300x300 image to 1x90000\n",
    "        image = fits.open(pcpath+f)[0].data\n",
    "        imagesXpoor.append(np.array([fx(image) for fx in metadata_funcs]))\n",
    "        labelsypoor.append('poor_coverage')\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f24d04",
   "metadata": {},
   "source": [
    "Now that we have the arrays filled in, we need to separate them into training and validation data. Typically we would do something like\n",
    "```\n",
    "imagesXtrain, imagesXtest, labelsytrain, labelsytest = train_test_split(imagesX, labelsy,\\\n",
    "                                                                        test_size=0.2, random_state=46)\n",
    "```                                                                        \n",
    "but it's more complicated here. For the good coverage (detections + nondetections path), we can simply split the array on the training percentage (typically 80%). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8a7006",
   "metadata": {},
   "outputs": [],
   "source": [
    "trsplit = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1536b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesXgood_train = imagesXgood[0:int(trsplit*len(imagesXgood))]\n",
    "labelsygood_train = labelsygood[0:int(trsplit*len(imagesXgood))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5755c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesXgood_test = imagesXgood[int(trsplit*len(imagesXgood)):]\n",
    "labelsygood_test = labelsygood[int(trsplit*len(imagesXgood)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876bcac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (len(imagesXgood_train)+len(imagesXgood_test))==len(imagesXgood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48d1f0d",
   "metadata": {},
   "source": [
    "For the poor coverage, however, most of our data are transformations of about 150 original images. We need to ensure that the validation dataset includes only fresh images (and their transformations), so that the classifier does not \"see\" a training image while testing its accuracy. Some of our metadata metrics (e.g. number of zero pixels) could be invariant with the transformation (e.g. rotation), so we want to ensure that our validation is not biased by the classifier already having seen a variant of the image.\n",
    "\n",
    "Fortunately, `os.listdir` reads the files in order, so we just need to figure out the first original image near ~80% for training, and use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2754a70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "npc = len(imagesXpoor) # number of poor images\n",
    "perc80 = int(0.8*len(imagesXpoor))\n",
    "print(perc80)\n",
    "print(os.listdir(pcpath)[perc80])\n",
    "print('----')\n",
    "\n",
    "for i, nm in enumerate(os.listdir(pcpath)):\n",
    "    if i>(perc80-20) and i<(perc80+20):\n",
    "        print(i,i/npc,nm)\n",
    "#for i,nm in os.listdir(pcpath):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9c9112",
   "metadata": {},
   "source": [
    "The split lands us on group 20170, and we can work backwards to include all of them in the validation set. Group 20170 first appears at index 3045. So that's where we split the training and validation datasets for poor images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d2d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir(pcpath)[0:3045] # note this doesn't include group 20170\n",
    "#os.listdir(pcpath)[3045:] # note starts on first 20170 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc92aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesXpoor_train = imagesXpoor[0:3045]\n",
    "labelsypoor_train = labelsypoor[0:3045]\n",
    "imagesXpoor_test = imagesXpoor[3045:]\n",
    "labelsypoor_test = labelsypoor[3045:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9f94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(imagesXpoor_train) + len(imagesXpoor_test) == len(imagesXpoor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d239791d",
   "metadata": {},
   "source": [
    "Now that we've split it up appropriately, let's combine everything into a final training set and a final validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19724b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesXgood_train.extend(imagesXpoor_train)\n",
    "imagesXtrain = imagesXgood_train\n",
    "labelsygood_train.extend(labelsypoor_train)\n",
    "labelsytrain = labelsygood_train\n",
    "\n",
    "imagesXgood_test.extend(imagesXpoor_test)\n",
    "imagesXtest = imagesXgood_test\n",
    "labelsygood_test.extend(labelsypoor_test)\n",
    "labelsytest = labelsygood_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d8852",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imagesXtrain), len(imagesXtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50121a8",
   "metadata": {},
   "source": [
    "Now just shuffle the data to remove the pattern of file transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375dc5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesXtrain, labelsytrain = shuffle(imagesXtrain, labelsytrain, random_state=46)\n",
    "imagesXtest, labelsytest = shuffle(imagesXtest, labelsytest, random_state=46)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2814dc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Initiate Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c522bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4bf1ad",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f49a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# breakdown valiation sample\n",
    "labelsytrain = np.array(labelsytrain)\n",
    "labelsytest = np.array(labelsytest)\n",
    "print(\"Percent of poor coverage in training sample: {}\".format(len(labelsytrain[labelsytrain=='poor_coverage'])/len(labelsytrain)))\n",
    "print(\"Percent of poor coverage in validation sample: {}\".format(len(labelsytest[labelsytest=='poor_coverage'])/len(labelsytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c8d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(imagesXtrain, labelsytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70cfe03",
   "metadata": {},
   "source": [
    "## Test the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ccb557",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(imagesXtest)\n",
    "print(\"Accuracy: \", accuracy_score(labelsytest,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931eac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "feature_names = [f.__name__ for f in metadata_funcs]\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.bar(feature_names, importances, yerr=std)\n",
    "plt.gca().set_xticklabels(feature_names, fontsize=8)\n",
    "plt.show()\n",
    "print(np.sum(importances))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357741d6",
   "metadata": {},
   "source": [
    "## Test individual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d93f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = fits.open(\"/srv/two/zhutchen/rosat_xray_stacker/g3rassimages/eco/RASS-Int_Broad_grp10300_ECO06627.fits\")\n",
    "image = image[0].data\n",
    "image_metadata = np.array([fx(image) for fx in metadata_funcs]).reshape(1,-1)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "print(clf.predict_proba(image_metadata))\n",
    "print(clf.predict(image_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34ace50",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = fits.open(\"/srv/scratch/zhutchen/khess_images/poor_coverage/RASS-Int_Hard_grp11771.0_.fits\")\n",
    "image = image[0].data\n",
    "image_metadata = np.array([fx(image) for fx in metadata_funcs]).reshape(1,-1)\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "print(clf.predict_proba(image_metadata))\n",
    "print(clf.predict(image_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295973b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = fits.open(\"/srv/two/zhutchen/rosat_xray_stacker/g3rassimages/eco/RASS-Int_Soft_grp10003_ECO05407.fits\")\n",
    "image = image[0].data\n",
    "image_metadata = np.array([fx(image) for fx in metadata_funcs]).reshape(1,-1)\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "print(clf.predict_proba(image_metadata))\n",
    "print(clf.predict(image_metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d54c35c",
   "metadata": {},
   "source": [
    "## Test on all the original poor coverage images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92523bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "origtestimages=[]\n",
    "origtestlabels=[]\n",
    "\n",
    "origpcpath = \"/srv/scratch/zhutchen/khess_images/poor_coverage/\"\n",
    "for f in os.listdir(origpcpath):\n",
    "    if f.endswith('.fits'):\n",
    "        #imagesX.append(np.array(fits.open(pcpath+f)[0].data).flatten()) #flatten each 300x300 image to 1x90000\n",
    "        image = fits.open(pcpath+f)[0].data\n",
    "        origtestimages.append(np.array([fx(image) for fx in metadata_funcs]))\n",
    "        origtestlabels.append('poor_coverage')\n",
    "        i+=1\n",
    "\n",
    "norig = len(origtestimages)\n",
    "print(norig)\n",
    "        \n",
    "origtestimages.extend(imagesXgood[int(trsplit*len(imagesXgood)):][0:norig])\n",
    "origtestlabels.extend(labelsygood[int(trsplit*len(labelsygood)):][0:norig])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf53c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(origtestimages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2244b3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(origtestimages)\n",
    "print(\"Accuracy: \", accuracy_score(origtestlabels,preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5009a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
